{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seasonal-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educated-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027364157827046952"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sfdmap\n",
    "\n",
    "m = sfdmap.SFDMap('../../DATA/sfddata-master/')\n",
    "\n",
    "m.ebv(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "august-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_BINS = 360\n",
    "ZMIN = 0.0\n",
    "ZMAX = 1.0\n",
    "BIN_SIZE = (ZMAX - ZMIN) / NB_BINS\n",
    "range_z = np.linspace(ZMIN, ZMAX, NB_BINS + 1)[:NB_BINS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "based-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns = ['ZBEST','gFKronFlux', 'rFKronFlux', 'iFKronFlux', 'zFKronFlux',\n",
    "       'yFKronFlux', 'gFPSFFlux', 'rFPSFFlux', 'iFPSFFlux',\n",
    "       'zFPSFFlux', 'yFPSFFlux', 'gFApFlux', 'rFApFlux', 'iFApFlux',\n",
    "       'zFApFlux', 'yFApFlux','gFmeanflxR5', 'rFmeanflxR5', 'iFmeanflxR5',\n",
    "       'zFmeanflxR5', 'yFmeanflxR5','gFmeanflxR6',\n",
    "       'rFmeanflxR6', 'iFmeanflxR6', 'zFmeanflxR6', 'yFmeanflxR6',\n",
    "       'gFmeanflxR7', 'rFmeanflxR7', 'iFmeanflxR7',\n",
    "       'zFmeanflxR7', 'yFmeanflxR7','raMean','decMean']\n",
    "\n",
    "X_COLUMNS = ['gFKronFlux', 'rFKronFlux', 'iFKronFlux', 'zFKronFlux',\n",
    "       'yFKronFlux', 'gFPSFFlux', 'rFPSFFlux', 'iFPSFFlux',\n",
    "       'zFPSFFlux', 'yFPSFFlux', 'gFApFlux', 'rFApFlux', 'iFApFlux',\n",
    "       'zFApFlux', 'yFApFlux','gFmeanflxR5', 'rFmeanflxR5', 'iFmeanflxR5',\n",
    "       'zFmeanflxR5', 'yFmeanflxR5','gFmeanflxR6',\n",
    "       'rFmeanflxR6', 'iFmeanflxR6', 'zFmeanflxR6', 'yFmeanflxR6',\n",
    "       'gFmeanflxR7', 'rFmeanflxR7', 'iFmeanflxR7',\n",
    "       'zFmeanflxR7', 'yFmeanflxR7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('./../../DATA/new_MAST_RETURNED_DF/no_repeats/no_repeats.csv',usecols=use_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "registered-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA = DF['raMean'].values\n",
    "DEC = DF['decMean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suited-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTINCTIONS = m.ebv(RA,DEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporate-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = DF['ZBEST'].values\n",
    "X = DF[X_COLUMNS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bearing-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933152, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X,EXTINCTIONS[:,None]),axis=1)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accurate-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair down to Y < 1\n",
    "X = X[Y<ZMAX]\n",
    "Y = Y[Y<ZMAX]\n",
    "\n",
    "X = X[Y>=ZMIN]\n",
    "Y = Y[Y>=ZMIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-exposure",
   "metadata": {},
   "source": [
    "# Next we need to convert fluxes to luptitudes (allows us to deal with negative flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "english-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = -2.5/ln(10) * [asinh((f/f0)/(2b)) + ln(b)]\n",
    "\n",
    "#The asinh magnitudes are characterized by a softening parameter b, the typical 1-sigma \n",
    "#noise of the sky in a PSF aperture in 1'' seeing. The relation between detected flux f and asinh magnitude m is:\n",
    "\n",
    "f_0 = 3631 #Jy\n",
    "\n",
    "#https://iopscience.iop.org/article/10.1088/0004-637X/756/2/158/pdf table1\n",
    "\n",
    "#1 square arcsecond sky background magnitude, use it to find b\n",
    "g_mu = 21.92\n",
    "r_mu = 20.83\n",
    "i_mu = 19.79\n",
    "z_mu = 19.24\n",
    "y_mu = 18.24\n",
    "\n",
    "b_g = np.exp((g_mu*np.log(10)/-2.5) - np.arcsinh((1/(2*f_0))))\n",
    "b_r = np.exp((r_mu*np.log(10)/-2.5) - np.arcsinh((1/(2*f_0))))\n",
    "b_i = np.exp((i_mu*np.log(10)/-2.5) - np.arcsinh((1/(2*f_0))))\n",
    "b_z = np.exp((z_mu*np.log(10)/-2.5) - np.arcsinh((1/(2*f_0))))\n",
    "b_y = np.exp((y_mu*np.log(10)/-2.5) - np.arcsinh((1/(2*f_0))))\n",
    "\n",
    "def convert_flux_to_luptitude(f,b,f_0=3631):\n",
    "    return -2.5/np.log(10) * (np.arcsinh((f/f_0)/(2*b)) + np.log(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "persistent-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g\n",
    "X[:,[0,5,10,15,20,25]] = convert_flux_to_luptitude(X[:,[0,5,10,15,20,25]],b=b_g)\n",
    "\n",
    "#r\n",
    "X[:,[1,6,11,16,21,26]] = convert_flux_to_luptitude(X[:,[1,6,11,16,21,26]],b=b_r)\n",
    "\n",
    "#i\n",
    "X[:,[2,7,12,17,22,27]] = convert_flux_to_luptitude(X[:,[2,7,12,17,22,27]],b=b_i)\n",
    "\n",
    "#z\n",
    "X[:,[3,8,13,18,23,28]] = convert_flux_to_luptitude(X[:,[3,8,13,18,23,28]],b=b_z)\n",
    "\n",
    "#y\n",
    "X[:,[4,9,14,19,24,29]] = convert_flux_to_luptitude(X[:,[4,9,14,19,24,29]],b=b_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "declared-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932381, 31)\n"
     ]
    }
   ],
   "source": [
    "#Robust to outliers\n",
    "\n",
    "MEANS = np.median(X,axis=0)\n",
    "IQR = np.quantile(X,axis=0,q=[0.75,0.25])\n",
    "STDS = (IQR[0,] - IQR[1,]) / 1.34896\n",
    "\n",
    "\n",
    "X = (X - MEANS)/STDS\n",
    "\n",
    "#robust to missing data\n",
    "X[np.isnan(X)] = -20\n",
    "#Fix outliers\n",
    "X[X<-20] = -20\n",
    "X[X>20] = 20\n",
    "\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baking-terry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.70654578, 17.77948707, 17.34226094, 17.1227873 , 16.92087669,\n",
       "       19.73947441, 18.89279411, 18.4077393 , 18.1311733 , 17.64741402,\n",
       "       19.01595669, 18.16447837, 17.73199409, 17.50486095, 17.20389615,\n",
       "       19.07834251, 18.16996592, 17.71492073, 17.44861273, 17.15508793,\n",
       "       18.79100201, 17.89569908, 17.45774026, 17.20338482, 16.93640741,\n",
       "       18.62759241, 17.7453392 , 17.31341498, 17.06194499, 16.79030564,\n",
       "        0.02543223])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "auburn-alexander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7657395 , 1.24853534, 1.08151972, 1.03490545, 0.87252421,\n",
       "       1.32486758, 0.9222839 , 0.73701807, 0.65002723, 0.41779001,\n",
       "       1.51554956, 1.05734494, 0.89939638, 0.82754093, 0.63381611,\n",
       "       1.48411417, 1.05425943, 0.89979008, 0.83934385, 0.64990996,\n",
       "       1.54735158, 1.10985163, 0.96460099, 0.90685922, 0.74507053,\n",
       "       1.57813401, 1.14290345, 1.00162105, 0.94634726, 0.80124359,\n",
       "       0.01687839])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-contact",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "matched-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make into classes\n",
    "Y_classes = np.round(Y * NB_BINS,0).astype(np.int32) #0-360, need to correct rounding up to 359\n",
    "Y_classes[Y_classes>=NB_BINS] = NB_BINS-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-berlin",
   "metadata": {},
   "source": [
    "# Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "convertible-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(X))\n",
    "SEED=0\n",
    "random.seed(SEED)\n",
    "\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[int(0*len(indices)):int(0.8*len(indices))]\n",
    "test_indices = indices[int(0.8*len(indices)):int(0.9*len(indices))]\n",
    "val_indices = indices[int(0.9*len(indices)):int(1.0*len(indices))]\n",
    "\n",
    "\n",
    "X_train = X[train_indices]\n",
    "Y_train = Y_classes[train_indices]\n",
    "\n",
    "X_test = X[test_indices]\n",
    "Y_test = Y_classes[test_indices]\n",
    "\n",
    "Y_test_real = Y[test_indices]\n",
    "\n",
    "X_val = X[val_indices]\n",
    "Y_val = Y_classes[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-prophet",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "future-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    INPUT = tf.keras.layers.Input(31)\n",
    "    \n",
    "    DENSE1 = tf.keras.layers.Dense(256,activation=tf.keras.layers.LeakyReLU(),kernel_initializer=tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(1e-5))(INPUT)\n",
    "    DROP1 = tf.keras.layers.Dropout(0.05)(DENSE1)\n",
    "    \n",
    "    DENSE2 = tf.keras.layers.Dense(1024,activation=tf.keras.layers.LeakyReLU(),kernel_initializer=tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(1e-5))(DROP1)\n",
    "    DROP2 = tf.keras.layers.Dropout(0.05)(DENSE2)\n",
    "    \n",
    "    DENSE3 = tf.keras.layers.Dense(1024,activation=tf.keras.layers.LeakyReLU(),kernel_initializer=tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(1e-5))(DROP2)\n",
    "    DROP3 = tf.keras.layers.Dropout(0.05)(DENSE3)\n",
    "    \n",
    "    DENSE4 = tf.keras.layers.Dense(1024,activation=tf.keras.layers.LeakyReLU(),kernel_initializer=tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(1e-5))(DROP3)\n",
    "    \n",
    "    OUTPUT = tf.keras.layers.Dense(360,activation=tf.keras.activations.softmax)(DENSE4)\n",
    "    \n",
    "    model = tf.keras.Model(INPUT,OUTPUT)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "about-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "mymodel = model()\n",
    "\n",
    "filepath='./MLP_luptons_class_3-21-21.hdf5'\n",
    "CB = tf.keras.callbacks.ModelCheckpoint(filepath,verbose=1)\n",
    "\n",
    "mymodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "grave-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5828/5828 [==============================] - 27s 4ms/step - loss: 4.4510 - val_loss: 3.8324\n",
      "\n",
      "Epoch 00001: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 2/50\n",
      "5828/5828 [==============================] - 26s 5ms/step - loss: 3.8365 - val_loss: 3.7281\n",
      "\n",
      "Epoch 00002: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 3/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.7377 - val_loss: 3.6690\n",
      "\n",
      "Epoch 00003: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 4/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.6887 - val_loss: 3.6439\n",
      "\n",
      "Epoch 00004: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 5/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.6572 - val_loss: 3.6214\n",
      "\n",
      "Epoch 00005: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 6/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.6348 - val_loss: 3.6115\n",
      "\n",
      "Epoch 00006: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 7/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.6193 - val_loss: 3.5957\n",
      "\n",
      "Epoch 00007: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 8/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.6060 - val_loss: 3.5735\n",
      "\n",
      "Epoch 00008: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 9/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5892 - val_loss: 3.5763\n",
      "\n",
      "Epoch 00009: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 10/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5748 - val_loss: 3.5588\n",
      "\n",
      "Epoch 00010: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 11/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5643 - val_loss: 3.5463\n",
      "\n",
      "Epoch 00011: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 12/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5583 - val_loss: 3.5506\n",
      "\n",
      "Epoch 00012: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 13/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5472 - val_loss: 3.5301\n",
      "\n",
      "Epoch 00013: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 14/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5410 - val_loss: 3.5230\n",
      "\n",
      "Epoch 00014: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 15/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5344 - val_loss: 3.5316\n",
      "\n",
      "Epoch 00015: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 16/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5288 - val_loss: 3.5239\n",
      "\n",
      "Epoch 00016: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 17/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5198 - val_loss: 3.5217\n",
      "\n",
      "Epoch 00017: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 18/50\n",
      "5828/5828 [==============================] - 28s 5ms/step - loss: 3.5151 - val_loss: 3.5127\n",
      "\n",
      "Epoch 00018: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 19/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5098 - val_loss: 3.5073\n",
      "\n",
      "Epoch 00019: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 20/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5057 - val_loss: 3.5127\n",
      "\n",
      "Epoch 00020: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 21/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.5007 - val_loss: 3.5165\n",
      "\n",
      "Epoch 00021: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 22/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4964 - val_loss: 3.4977\n",
      "\n",
      "Epoch 00022: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 23/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4927 - val_loss: 3.5001\n",
      "\n",
      "Epoch 00023: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 24/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4862 - val_loss: 3.4949\n",
      "\n",
      "Epoch 00024: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 25/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4850 - val_loss: 3.4906\n",
      "\n",
      "Epoch 00025: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 26/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4833 - val_loss: 3.5073\n",
      "\n",
      "Epoch 00026: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 27/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4801 - val_loss: 3.5030\n",
      "\n",
      "Epoch 00027: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 28/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4741 - val_loss: 3.4897\n",
      "\n",
      "Epoch 00028: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 29/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4679 - val_loss: 3.4945\n",
      "\n",
      "Epoch 00029: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 30/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4685 - val_loss: 3.4990\n",
      "\n",
      "Epoch 00030: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 31/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4646 - val_loss: 3.4904\n",
      "\n",
      "Epoch 00031: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 32/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4619 - val_loss: 3.4944\n",
      "\n",
      "Epoch 00032: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 33/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4590 - val_loss: 3.4868\n",
      "\n",
      "Epoch 00033: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 34/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4572 - val_loss: 3.4788\n",
      "\n",
      "Epoch 00034: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 35/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4528 - val_loss: 3.4806\n",
      "\n",
      "Epoch 00035: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 36/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4515 - val_loss: 3.4854\n",
      "\n",
      "Epoch 00036: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 37/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4505 - val_loss: 3.4782\n",
      "\n",
      "Epoch 00037: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 38/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4477 - val_loss: 3.4895\n",
      "\n",
      "Epoch 00038: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 39/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4472 - val_loss: 3.4817\n",
      "\n",
      "Epoch 00039: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 40/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4427 - val_loss: 3.4960\n",
      "\n",
      "Epoch 00040: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 41/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4405 - val_loss: 3.4811\n",
      "\n",
      "Epoch 00041: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 42/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4380 - val_loss: 3.4854\n",
      "\n",
      "Epoch 00042: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 43/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4348 - val_loss: 3.4756\n",
      "\n",
      "Epoch 00043: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 44/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4314 - val_loss: 3.4824\n",
      "\n",
      "Epoch 00044: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 45/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4319 - val_loss: 3.4803\n",
      "\n",
      "Epoch 00045: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 46/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4283 - val_loss: 3.4843\n",
      "\n",
      "Epoch 00046: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 47/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4284 - val_loss: 3.4879\n",
      "\n",
      "Epoch 00047: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 48/50\n",
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4253 - val_loss: 3.4802\n",
      "\n",
      "Epoch 00048: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 49/50\n",
      "5828/5828 [==============================] - 28s 5ms/step - loss: 3.4242 - val_loss: 3.4774\n",
      "\n",
      "Epoch 00049: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5828/5828 [==============================] - 27s 5ms/step - loss: 3.4231 - val_loss: 3.4785\n",
      "\n",
      "Epoch 00050: saving model to .\\MLP_luptons_class_3-21-21.hdf5\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    hist = mymodel.fit(X_train,Y_train,validation_data=(X_val,Y_val),batch_size=128,epochs=40,callbacks=[CB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "published-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "artificial-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = mymodel(X_test,training=False).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "placed-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OUT = np.sum(OUT*range_z,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "conventional-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=15\n",
    "\n",
    "plt.title('Example Posterior')\n",
    "plt.plot(range_z,OUT[index,:])\n",
    "plt.vlines(TEST_OUT[index],0,0.15,color='k',linestyle='dashed',label='Real Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stupid-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_scaled = (TEST_OUT - Y_test_real)/(1+Y_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "transsexual-vacuum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasquets Defintions: \n",
      "MAD:  0.0155\n",
      "BIAS:  0.002\n",
      "ETA:  1.1519 % 5 sigma_mad, percentage\n",
      " \n",
      "Becks Defintions\n",
      "O:  0.3057 %\n",
      "MAD:  0.0155\n",
      "STD:  0.0212\n",
      "BIAS:  0.0018\n",
      " \n",
      "Tarrio Defintions\n",
      "STD:  0.0257\n",
      "BIAS:  0.0018\n",
      "P0:  Actually they dont well define this metric\n",
      " \n",
      " \n",
      " \n",
      "Tarrio 2020s STD: 0.0298\n",
      "Tarrio 2020s BIAS: -2.01e-4\n",
      " \n",
      "Beck 2019s O: 1.89%\n",
      "Beck 2019s MAD: 0.0161\n",
      "Beck 2019s STD: 0.0322\n",
      "Beck 2019s BIAS: 5e-4\n"
     ]
    }
   ],
   "source": [
    "#Using Pasquet's definition\n",
    "\n",
    "MAD = 1.4826*np.median(abs(residuals_scaled - np.median(residuals_scaled)))\n",
    "BIAS = np.mean(residuals_scaled)\n",
    "ETA = np.sum(abs(residuals_scaled)>=5*MAD)/len(residuals_scaled)\n",
    "\n",
    "print('Pasquets Defintions: ')\n",
    "print('MAD: ',np.round(MAD,4))\n",
    "print('BIAS: ',np.round(BIAS,4))\n",
    "print('ETA: ',np.round(100*ETA,4),'% 5 sigma_mad, percentage')\n",
    "print(' ')\n",
    "print('Becks Defintions')\n",
    "print('O: ',np.round(100*np.sum(abs(residuals_scaled)>0.15)/len(residuals_scaled),4),'%')\n",
    "print('MAD: ',np.round(1.4826*np.median(abs(residuals_scaled[abs(residuals_scaled)<=0.15] - np.median(residuals_scaled[abs(residuals_scaled)<=0.15]))),4))\n",
    "print('STD: ',np.round(np.std(residuals_scaled[abs(residuals_scaled)<=0.15]),4))\n",
    "print('BIAS: ',np.round(np.mean(residuals_scaled[abs(residuals_scaled)<=0.15]),4))\n",
    "#Tarrio et al 2020 using multiple local linear regression\n",
    "#BIAS = -2e-4 (after remove 3 sigma outliers)\n",
    "#STD = 0.0298 \n",
    "#ETA = \n",
    "print(' ')\n",
    "print('Tarrio Defintions')\n",
    "print('STD: ',np.round(np.std(residuals_scaled),4))\n",
    "print('BIAS: ',np.round(np.mean(residuals_scaled[abs(residuals_scaled)<=3*np.std(residuals_scaled)]),4))\n",
    "print('P0: ','Actually they dont well define this metric')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Tarrio 2020s STD: 0.0298')\n",
    "print('Tarrio 2020s BIAS: -2.01e-4')\n",
    "#Beck 2020\n",
    "print(' ')\n",
    "print('Beck 2019s O: 1.89%')\n",
    "print('Beck 2019s MAD: 0.0161')\n",
    "print('Beck 2019s STD: 0.0322')\n",
    "print('Beck 2019s BIAS: 5e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "advanced-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIT(X,Out,title='title',string='plot.png',save=False,n_classes=180):\n",
    "    \"\"\"\n",
    "    X = spectro Z array\n",
    "    Out = probabilities array\n",
    "    \"\"\"\n",
    "    #print(np.shape(X))\n",
    "    X_true_bin = np.round((X/ZMAX)*(n_classes-1),0).astype(int)\n",
    "    X_true_bin[X_true_bin>=n_classes] = n_classes-1 \n",
    "    PIT = []\n",
    "\n",
    "    #print(np.shape(X_true_bin))\n",
    "    #print(np.shape(Out))\n",
    "    for i in range(len(X_true_bin)):\n",
    "        PIT.append(np.sum((Out[i,:])[0:X_true_bin[i]]))\n",
    "\n",
    "    PIT=np.asarray(PIT)\n",
    "\n",
    "    n_bins=n_classes\n",
    "    bins=np.linspace(0,1,n_bins)\n",
    "    #draw the line that is if it was a perfect distribution. it would have..\n",
    "    #len(PIT)/180 #number in each bin\n",
    "    plt.hlines((len(PIT)/n_bins),0,1,colors='k',linestyles='solid')\n",
    "    plt.xlim(0,1)\n",
    "    plt.hist(PIT,bins)\n",
    "    plt.title(title)\n",
    "    if save==True:\n",
    "        plt.savefig(string)\n",
    "    plt.show()\n",
    "\n",
    "    #catastropic outliers are thos with PIT values <0.0001 or >0.9999; a normal distribution would have 0.0002 fraction\n",
    "    catastropic_outlier_fraction = (len(PIT[PIT<0.0001]) + len(PIT[PIT>0.9999])) / len(PIT)\n",
    "    print(catastropic_outlier_fraction)\n",
    "    print(' ')\n",
    "    print(\"Normal distribution's fraction is 0.0002\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vital-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = mymodel(X_test,training=False).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "x = Y_test_real\n",
    "y = np.sum(range_z*Y_pred,1) #for categorical\n",
    "\n",
    "\n",
    "#CRPS, FOR CLASS ONLY:\n",
    "z_bins = Y_test\n",
    "CRPS=np.zeros(len(Y_test))\n",
    "for i in range(len(CRPS)):\n",
    "    CRPS[i] = (np.sum((np.cumsum(Y_pred[i,0:z_bins[i]]))**2) + np.sum((np.cumsum(Y_pred[i,z_bins[i]::])-1)**2)) * BIN_SIZE\n",
    "CRPS_estimator=np.mean(CRPS)\n",
    "print('CRPS estimator: ',CRPS_estimator)\n",
    "#summary stats\n",
    "\n",
    "#KDE plot\n",
    "nbins=300\n",
    "x=x[::25]\n",
    "y=y[::25]\n",
    "\n",
    "k = kde.gaussian_kde([x,y])\n",
    "xi, yi = np.mgrid[0:ZMAX:nbins*1j, 0:ZMAX:nbins*1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    " \n",
    "# Make the plot\n",
    "plt.pcolormesh(xi, yi, zi.reshape(xi.shape), cmap='plasma')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim(0,0.6)\n",
    "plt.ylim(0,0.6)\n",
    "plt.title('MLP: every 25th point')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "PIT(Y_test/NB_BINS,Y_pred,'MLP PIT',n_classes=NB_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-health",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
